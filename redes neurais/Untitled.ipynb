{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatório do trabalho\n",
    "==============\n",
    "**Nome:** Álvaro Leandro Cavalcante Carneiro\n",
    "**Linguagem utilizada:** Python 3.6\n",
    "\n",
    "Os códigos e o relatório foram desenvolvidos em um Jupyter notebook e sua versão online pode ser encontrada aqui: https://colab.research.google.com/drive/1HQIBTnHCrcSrfAUOsx7836wZzDnQ9Fhd?usp=sharing. Nessa versão é possível executar novamente os algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual o problema ? \n",
    "Utilizar uma rede neural no modelo perceptron para identificar 3 classes de flores baseados em suas características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas\n",
    "Ferramentas usadas no processo de desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação da função de soma\n",
    "O perceptron, assim como o perceptron multicamadas, possui diversas operações que são realizadas entre os neurônios, esses operações foram representadas em diferentes métodos peqenos.\n",
    "O primeiro deles é a função de soma, que acontece em todos os neurônios, somando o valor do produto da multiplicação entre o neurônio adjacente anterior com o peso da sinapse artificial.\n",
    "Isso foi feito utilizando a biblioteca do numpy por uma questão de performance, onde a função dot nos retorna o produto escalar que desejamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def somatoria(entradas, pesos):\n",
    "    return np.dot(entradas, pesos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de ativação\n",
    "A função de ativação por default no perceptron é a chamada \"step function (função degrau)\", onde o neurônio artificial é excitado ou não baseado em um treshold (limiar) pré definido.\n",
    "Nesse caso, se o valor do neurônio for maior que 0 ele retorna o 1, excitando a célula, caso contrário, retorna 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_ativacao(soma):\n",
    "    if soma > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de atualização de peso\n",
    "A atualização de pesos no perceptron é definida pela seguinte formula:\n",
    "\n",
    "\n",
    "Com isso, conseguimos ajustar os pesos seguindo um taxa de aprendizado como o tamanho do nosso \"passo\" além de levar em consideração a grandeza da entrada e o quanto o valor errou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_peso(entrada, peso, erro, tx_aprendizado = 0.2):\n",
    "    novo_peso = peso + (tx_aprendizado * entrada * erro)\n",
    "    print('peso atualizado', novo_peso)\n",
    "    return novo_peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do perceptron\n",
    "A função de treinamento recebe o número de épocas que iremos executar nosso perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar(epocas):\n",
    "    execucoes = 0\n",
    "    while execucoes < epocas:\n",
    "        precisao = 100\n",
    "        iteracao = 0\n",
    "\n",
    "        np.random.shuffle(previsores.values) # embaralhar os valores dos previsores, por que sem isso, podemos ter sempre uma ordem fixa de ajuste de pesos, prejudicando a rede\n",
    "\n",
    "        for i in previsores.values:\n",
    "            entradas = i   \n",
    "            soma = somatoria(entradas, pesos)\n",
    "        \n",
    "            ativacao = funcao_ativacao(soma)\n",
    "        \n",
    "            erro = funcao_custo(classe[iteracao], ativacao) # baseado no meu resultado previsto, dado na última função de ativação.\n",
    "        \n",
    "            if erro > 0:\n",
    "                precisao -= 100 / len(previsores) \n",
    "                print('Precisão: ', precisao)\n",
    "                count = 0\n",
    "                    \n",
    "                for i in entradas:\n",
    "                    novo_peso = atualizar_peso(i, pesos[count], erro)\n",
    "                    pesos[count] = novo_peso\n",
    "                    count += 1\n",
    "            \n",
    "            iteracao += 1\n",
    "        \n",
    "        execucoes += 1\n",
    "    print('Precisão final: ', precisao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinar(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
