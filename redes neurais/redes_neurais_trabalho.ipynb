{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatório do trabalho\n",
    "==============\n",
    "**Nome:** Álvaro Leandro Cavalcante Carneiro\n",
    "**Linguagem utilizada:** Python 3.6\n",
    "\n",
    "Os códigos e o relatório foram desenvolvidos em um Jupyter notebook e sua versão online pode ser encontrada aqui: https://colab.research.google.com/drive/1HQIBTnHCrcSrfAUOsx7836wZzDnQ9Fhd?usp=sharing. Nessa versão é possível executar novamente os algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qual o problema ? \n",
    "Utilizar uma rede neural no modelo perceptron para identificar 3 classes de flores baseados em suas características de tamanho de pétalada e sépala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas\n",
    "Ferramentas usadas no processo de desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória dos Dados (AED)\n",
    "Vamos entender um pouco mais do nosso dataset, e deixar os dados em um formato que seja favorável para nossa rede neural perceptron.\n",
    "\n",
    "O primeiro passo foi ler o arquivo baixado aqui: http://archive.ics.uci.edu/ml/datasets/Iris.\n",
    "O arquivo em questão não possuia colunas, portanto eu modifiquei o mesmo para adicionar o nome das colunas na primeira linha e deixar o arquivo no formato .CSV ao invés do .DATA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('/home/alvaro/Documentos/mestrado/computação bio/redes neurais/datasets/iris2.csv', header = 0)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um passo inicial importante é verificar se o nosso dataset possui inconsistências quanto aos valores, podendo ser algum outlier, ruído, valor vazio, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos:\n",
      "sepal-length    0\n",
      "sepal-width     0\n",
      "petal-length    0\n",
      "petal-width     0\n",
      "class           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal-length  sepal-width  petal-length  petal-width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Valores nulos:')\n",
    "print(dataframe.isna().sum())\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos atributos previsores\n",
    "O método *isnul()* nos mostrou que não há nenhum registro vazio no nosso dataset, além disso, é possível observar que os valores também parecem estar todos coerentes, sem a presença de outliers, como podemos notar pelo desvio padrão e mínimo e máximo de cada coluna.\n",
    "\n",
    "Todavia, existe uma variação relativamente grande dentro do nosso domínio de atributos previsores. O atributo *petal-width* por exemplo, tem uma média de valor de 1.1, enquanto o *sepal-length* possui uma média de 5.8, portanto se faz necessário a padronização dos valores, para que nosso ajuste dos pesos não seja muito influenciado por essa diferença no tamanho da entrada. \n",
    "\n",
    "O tipo de normalização escolhido foi o **Z-score**, de forma arbitrária, por ser bastante comum em problemas como esse. Sua fórmula é bastante simples e foi representada no método *normalizacao_z_score*.\n",
    "\n",
    "Ainda um pouco antes de fazer a normalização, dividi nosso *dataframe* em uma variável chamada **previsores** e outra chamada **classe**, como o nome sugere, os previsores são as colunas com as características das flores que serão usadas para tentar ajustar nossos pesos da rede de maneira à generalizar uma solução que encontre as classes corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = dataframe.iloc[:, 0:4] \n",
    "classe = dataframe['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao_z_score(valor):\n",
    "    media = previsores[valor.name].mean()\n",
    "    desvio_padrao = previsores[valor.name].std()\n",
    "\n",
    "    return (valor - media) / desvio_padrao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método *apply()* com a **lambda** aplicam o processo matemático do nosso método de normalização em cada um dos registros do *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.897674</td>\n",
       "      <td>1.028611</td>\n",
       "      <td>-1.336794</td>\n",
       "      <td>-1.308593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.139200</td>\n",
       "      <td>-0.124540</td>\n",
       "      <td>-1.336794</td>\n",
       "      <td>-1.308593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.380727</td>\n",
       "      <td>0.336720</td>\n",
       "      <td>-1.393470</td>\n",
       "      <td>-1.308593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.501490</td>\n",
       "      <td>0.106090</td>\n",
       "      <td>-1.280118</td>\n",
       "      <td>-1.308593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.018437</td>\n",
       "      <td>1.259242</td>\n",
       "      <td>-1.336794</td>\n",
       "      <td>-1.308593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width\n",
       "0     -0.897674     1.028611     -1.336794    -1.308593\n",
       "1     -1.139200    -0.124540     -1.336794    -1.308593\n",
       "2     -1.380727     0.336720     -1.393470    -1.308593\n",
       "3     -1.501490     0.106090     -1.280118    -1.308593\n",
       "4     -1.018437     1.259242     -1.336794    -1.308593"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores = previsores.apply(lambda row: normalizacao_z_score(row))\n",
    "previsores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratando valores categóricos\n",
    "Podemos ver agora que nossos valores estão em uma escala completamente diferente, todavia isso os torna mais coerente de serem trabalhados.\n",
    "\n",
    "O próximo passo será transformar o valor da nossa classe de categórico para discreto, para que seja possível calcular o erro da saída por exemplo.\n",
    "\n",
    "O primeiro passo para isso foi criar um método que gera uma estrutura de dicionário dinâmica, baseado na quantidade de classes do problema que está sendo tratado. Para isso, basta percorrer a classe existente e atribuir um valor inteiro para cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicionario_classes(classe):\n",
    "    dict_classes = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in classe.unique():\n",
    "        dict_classes[i] = count\n",
    "        count += 1\n",
    "        \n",
    "    return dict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "dict_classes = get_dicionario_classes(classe)\n",
    "print(dict_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver acima os valores que nosso método atribuiu para cada uma das classes.\n",
    "\n",
    "Basta agora repetir o processos anterior de usar o método *apply()*, porém agora passando no *lambda* o método que vai atribuir a classe a seu determinado valor no dicionário que criamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe no formato numérico 2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def transformar_categorico_em_numerico(valor, dict_classes):\n",
    "    return dict_classes[valor]\n",
    "    \n",
    "classe = classe.apply(lambda row: transformar_categorico_em_numerico(row, dict_classes))\n",
    "print('Classe no formato numérico', classe.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lidando com problemas multi-classe\n",
    "O problema em questão é multi-classe, ou seja, possuímos mais de duas classes como resposta na nossa camada de saída, podendo ser, íris-setosa, versicolor e virginica.\n",
    "Para problemas binários utilizar um único neurônio com a saída de 0 e 1 nos basta, todavia aqui, vamos precisar criar um novo neurônio para cada classe, totalizando 3 na nossa camada de saída.\n",
    "\n",
    "Além de modificar a estrutura da rede neural, também vamos precisar codificar nossos valores, uma vez que, ao invés de um valor escalar vamos trabalhar com um array na saída da rede, sendo ele representado por: [1,0,0], [0,1,0] e [0,0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_classe():\n",
    "    classe_codificada = {}\n",
    "    array_classe = [1] + [0] * (len(classe.unique()) - 1) #cria um array dinâmico baseado na \n",
    "    #quantidade de classes, é [1,0,0] para esse problema mas poderia ser [1,0,0,0....,0].\n",
    "    count = 1    \n",
    "    classe_codificada[0] = array_classe.copy()\n",
    "    \n",
    "    for i in range(len(classe.unique()) - 1):\n",
    "        array_classe[count - 1] = 0\n",
    "        array_classe[count] = 1     \n",
    "        classe_codificada[count] = array_classe.copy()\n",
    "        count += 1\n",
    "    \n",
    "    return classe_codificada      \n",
    "\n",
    "classe_codificada = codificar_classe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 0, 0], 1: [0, 1, 0], 2: [0, 0, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_codificada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia do método *codificar_classe* é criar mais um dicionário, como podemos ver acima, onde cada posição representa uma classe codificada em um array de binários. O tamanho desse array é dinâmico dependendo do número de classes e a ideia é ir movimentando o valor do 1 conforme as iterações.\n",
    "\n",
    "Feito isso, basta repetir o processo para substituir o valor da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [1, 0, 0]\n",
      "1    [1, 0, 0]\n",
      "2    [1, 0, 0]\n",
      "3    [1, 0, 0]\n",
      "4    [1, 0, 0]\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def substituir_classe_codificada(valor, classe_codificada):\n",
    "    return classe_codificada[valor]\n",
    "\n",
    "classe = classe.apply(lambda row: substituir_classe_codificada(row, classe_codificada))\n",
    "print(classe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, a classe agora está em uma estrutura que vai suportar o problema multi-classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização dos pesos\n",
    "Os pesos serão inicializados de forma aleatória para então serem gradativamente ajustados conforme a rede neural converge.\n",
    "Para isso, foi criado o método *inicializar_pesos*, que percorre cada um dos neurônios e gera um vetor da quantidade de pesos que ele possui baseado nas suas conexões sinapticas com os neurônios da próxima camada.\n",
    "\n",
    "Além disso, nosso método também recebe um parâmetro chamado dominio, que é o intervalo de valores que os pesos serão gerados, os testes a princípio foram realizados em um domínio de [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_pesos(dominio):\n",
    "    pesos_final = []\n",
    "    \n",
    "    for i in range(len(previsores.columns)):\n",
    "        pesos = [] \n",
    "        for j in range(len(dict_classes)):\n",
    "            pesos.append(random.uniform(dominio[0], dominio[1]))\n",
    "        pesos_final.append(pesos)\n",
    "    return pesos_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos: [[0.2792888346935375, 0.650936129351441, 0.5877349714324628], [0.06968998177646468, 0.521682714640433, 0.2283172562238035], [0.12142492407255268, 0.604884070630378, 0.7739583379263297], [0.12064904021797795, 0.3598282526162032, 0.5248123922348522]]\n"
     ]
    }
   ],
   "source": [
    "pesos = inicializar_pesos()\n",
    "print('Pesos:', pesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, nosso array de pesos para esse problema possui 4 posições com 3 pesos em cada uma das posições, isso acontece por que possuímos 4 neurônios (nosso atributos de entrada) conectados à 3 neurônios (um neurônio para cada saída possível), portanto cada um dos 4 neurônios possui 3 pesos (conexões) cada um. \n",
    "\n",
    "Para obter o número de conexões por camada basta multiplicar o número de neurônios da camada atual pelos número de neurônios na próxima camada, dessa forma temos: 4 * 3 = 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação da função de soma\n",
    "O perceptron, assim como o perceptron multicamadas, possui diversas operações que são realizadas entre os neurônios, esses operações foram representadas em diferentes métodos peqenos.\n",
    "O primeiro deles é a função de soma, que acontece em todos os neurônios, somando o valor do produto da multiplicação entre o neurônio adjacente anterior com o peso da sinapse artificial.\n",
    "Isso foi feito utilizando a biblioteca do numpy por uma questão de performance, onde a função dot nos retorna o produto escalar que desejamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def somatoria(entradas, pesos):\n",
    "    return np.dot(entradas, pesos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de ativação\n",
    "A função de ativação por default no perceptron é a chamada \"step function (função degrau)\", onde o neurônio artificial é excitado ou não baseado em um treshold (limiar) pré definido.\n",
    "Nesse caso, se o valor do neurônio for maior que 0 ele retorna o 1, excitando a célula, caso contrário, retorna 0.\n",
    "\n",
    "Por ser um problema multiclasse, foi criado um *for* para percorrer o array da classe e excitar todas as posições em que o valor é maior que 0. \n",
    "\n",
    "Claro que isso acaba gerando um problema onde mais de um neurônio por vez na camada de saída é excitado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_ativacao_step(soma):\n",
    "    ativacao = []\n",
    "    for i in soma:\n",
    "        if i > 0:\n",
    "            ativacao.append(1)\n",
    "        else:\n",
    "            ativacao.append(0)\n",
    "\n",
    "    return ativacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de custo\n",
    "A função de custo é a responsável por calcular o erro da nossa rede neural, ao comparar o valor correto com o valor que foi previsto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_custo(valor_correto, valor_previsto):\n",
    "    erro = list(abs(np.array(valor_correto) - np.array(valor_previsto)))\n",
    "    return sum(erro) # valor escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de atualização de peso\n",
    "A atualização de pesos no perceptron é definida pela seguinte formula:\n",
    "\n",
    "\n",
    "Com isso, conseguimos ajustar os pesos seguindo um taxa de aprendizado, basicamente o tamanho do nosso \"passo\", além de levar em consideração a grandeza da entrada e o quanto a previsão estava incorreta.\n",
    "\n",
    "Algo importante de se considerar é que o perceptron faz a atualização dos pesos POR REGISTRO, ou seja, a cada registro apresentado à rede neural que é classificado de forma incorreta gera uma atualização nos pesos, podendo dificultar a generalização dos pesos devido à sensibilidade aos dados contidos no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_peso(entrada, peso, erro, tx_aprendizado = 0.001):\n",
    "    novo_peso = peso + (tx_aprendizado * entrada * erro)\n",
    "    return novo_peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do perceptron\n",
    "A função de treinamento recebe o número de épocas que iremos executar nosso perceptron, onde cada época representa a passagem de todo o dataset na nossa rede. A estratégia seguida a princípio para atualização dos pesos é por registro, ou seja, para cada registro errado nós fazemos os ajustes nos pesos. Geralmente no perceptron multicamadas essa atualização é feita por épocas ou batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar(epocas, f_ativacao):\n",
    "    execucoes = 0\n",
    "    precisoes = [0]\n",
    "    while execucoes < epocas:\n",
    "        precisao = 0\n",
    "        iteracao = 0\n",
    "\n",
    "        np.random.shuffle(previsores.values) # embaralhar os valores dos previsores, por que sem isso, podemos ter sempre uma ordem fixa de ajuste de pesos, prejudicando a rede\n",
    "\n",
    "        for i in previsores.values:\n",
    "            entradas = i   \n",
    "            soma = somatoria(entradas, pesos)\n",
    "        \n",
    "            ativacao = f_ativacao(soma)\n",
    "        \n",
    "            erro = funcao_custo(classe[iteracao], ativacao) # baseado no meu resultado previsto, dado na última função de ativação.\n",
    "        \n",
    "            if erro > 0:\n",
    "                count = 0\n",
    "\n",
    "                for i in entradas:\n",
    "                    novo_peso = atualizar_peso(i, pesos[count], erro)\n",
    "                    pesos[count] = novo_peso\n",
    "                    count += 1\n",
    "            else:\n",
    "                precisao += 100 / len(previsores)\n",
    "                precisoes.append(precisao)\n",
    "\n",
    "            iteracao += 1\n",
    "        \n",
    "        execucoes += 1\n",
    "    return max(precisoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes no perceptron\n",
    "Uma vez que a rede perceptron foi criada só nós resta testar. Para isso, o algoritmo foi inicializado 50 vezes, sem nenhuma mudança nos dados, apenas gerando um conjunto inicial de pesos diferente para cada inicialização.\n",
    "\n",
    "As redes neurais são algoritmos extremamente estocásticos, o que faz com que sejam inclusive evitados em algumas áreas, portanto é interessante tentar treinar a rede várias vezes para tentar capturar seus melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor precisão da rede 12.666666666666663\n"
     ]
    }
   ],
   "source": [
    "precisao_rede = []\n",
    "for i in range(50):\n",
    "    pesos = inicializar_pesos([0, 1]) #iniciamos novamente os pesos para mudá-los em cada teste\n",
    "    precisao_rede.append(treinar(100, funcao_ativacao_step))\n",
    "\n",
    "print('Melhor precisão da rede', max(precisao_rede))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados iniciais e ZeroR\n",
    "Nossos testes inicias nos mostram uma precisão extremamente baixa, algo está definitivamente se comportando mal no algoritmo. Podemos ter certeza que o culpado é nosso algoritmo e não a base de dados devido à análise exploratória nos dados que foi feita anteriormente, além de do fato de ter o conhecimento de que é um problema linearmente separável.\n",
    "\n",
    "Para saber a precisão mínima que um algoritmo deve ter para ser considerado melhor do que não usar algoritmo algum ao fazer previsões é o \"zeroR\". Basicamente se classificarmos todos os nosso registros como pertencendo à classe majoritária, qual será nossa precisão?\n",
    "\n",
    "\n",
    "Nesse dataset as classes estão **normalmente distribuídas** em 3 partes iguais, fazendo com que nossa precisão majoritária sem algoritmos seja de **33%**.\n",
    "\n",
    "\n",
    "Todavia ainda que nosso algoritmo seja considerado útil com 34% de acerto, não faz sentido investir em algo com números tão baixos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de ativação sigmoid.\n",
    "Como foi dito anteriormente, utilizar a função degrau para ativação pode gerar no aumento dos erros, devido a possibilidade de excitar vários neurônios ao passar pelo limiar especificado.\n",
    "\n",
    "Portanto foi criado uma nova função de ativação baseado na sigmoid, definida pela seguinte fórmula:\n",
    "\n",
    "\n",
    "Com isso, nossos valores ficam em um intervalo de 0 e 1 e o neurônio escolhido para ser excitado é aquele com o maior valor. Dessa forma, já não temos mais o problema de excitar vários neurônios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_ativacao_sigmoid(soma):\n",
    "    resultado = list(1 / (1 + math.e ** -soma))\n",
    "    index_excitacao = resultado.index(max(resultado)) \n",
    "    resultado = [0] * len(soma)\n",
    "    resultado[index_excitacao] = 1\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor precisão da rede 38.666666666666664\n"
     ]
    }
   ],
   "source": [
    "precisao_rede = []\n",
    "for i in range(50):\n",
    "    pesos = inicializar_pesos([0, 1]) #iniciamos novamente os pesos para mudá-los em cada teste\n",
    "    precisao_rede.append(treinar(100, funcao_ativacao_sigmoid))\n",
    "\n",
    "print('Melhor precisão da rede', max(precisao_rede))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos melhorar consideravelmente os resultados com essa nova função de ativação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias\n",
    "Algo que podemos fazer para melhorar a generalização da rede é adicionar o Bias, sendo uma constante que será considerada como um neurônio na camada de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor precisão da rede 37.333333333333336\n"
     ]
    }
   ],
   "source": [
    "previsores['bias'] = 1\n",
    "precisao_rede = []\n",
    "for i in range(50):\n",
    "    pesos = inicializar_pesos([0, 1]) #iniciamos novamente os pesos para mudá-los em cada teste\n",
    "    precisao_rede.append(treinar(100, funcao_ativacao_sigmoid))\n",
    "\n",
    "print('Melhor precisão da rede', max(precisao_rede))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, a aplicação do bias também nos ajudo a melhorar os resultados da rede, chegando em torno de 70% de precisão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
